## Intro

This repo includes

- slides of **basicRL** tutorials made by Judy
- reading notes and some python implementations from **Reinforcement Learning an Introduction 2nd Edition** by Sutton and Barto
- some interesting extensions and papers throughout the reading

Here are some detailed notes of **basicRL**:

https://ha5ha6.github.io/judy_blog/basicrl/

https://ha5ha6.github.io/judy_blog/td/

Here are some classic implementations of **RL in control**:

https://ha5ha6.github.io/judy_blog/cartpole/

Let me know if you found any typo or mistakes :)

## Contents of Slides

**basicRL_1** - explanations of basic RL concepts like agent-environment interactions, (discrete/continuous) states, (discrete/continuous) actions, (the art of) rewards, (deterministic/stochastic) policies, (deterministic/stochastic) dynamics, and MDP

**basicRL_2** - explanations of the goal of RL, with ingredients like episode, history trajectory, return, discounting factor, value functions, optimal value functions and optimal policy

**basicRL_3** - explanations of the learning mechanism of RL, including Bellman equations, one-step update rules, generalized policy iteration, Q-learning and Cliff Walking example

## Interesting Papers

Dulac-Arnold, Gabriel, et al. "Deep reinforcement learning in large discrete action spaces." arXiv preprint arXiv:1512.07679 (2015).

Haarnoja, Tuomas, et al. "Learning to walk via deep reinforcement learning." arXiv preprint arXiv:1812.11103 (2018).

Fr√©maux, Nicolas, Henning Sprekeler, and Wulfram Gerstner. "Reinforcement learning using a continuous time actor-critic framework with spiking neurons." PLoS computational biology 9.4 (2013): e1003024.

Parisi, Simone, et al. "Long-Term Visitation Value for Deep Exploration in Sparse-Reward Reinforcement Learning." Algorithms 15.3 (2022): 81.

Sugiyama, Masashi, et al. "Geodesic Gaussian kernels for value function approximation." Autonomous Robots 25.3 (2008): 287-304.

Osogami, Takayuki, and Makoto Otsuka. "Seven neurons memorizing sequences of alphabetical images via spike-timing dependent plasticity." Scientific reports 5.1 (2015): 1-13.

Deisenroth, Marc Peter, Gerhard Neumann, and Jan Peters. "A survey on policy search for robotics." Foundations and trends in Robotics 2.1-2 (2013): 388-403.

Kober, Jens, J. Andrew Bagnell, and Jan Peters. "Reinforcement learning in robotics: A survey." The International Journal of Robotics Research 32.11 (2013): 1238-1274.

## Further Reading

**Neuro-Dynamic Programming** by Dimitri Bertsekas

**Algorithms for Reinforcement learning** by Csaba Szepesvari

**Markov Decision Processes in Artificial Intelligence** by Olivier Sigaud, Olivier Buffet
